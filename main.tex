\documentclass{article}



\usepackage[preprint]{style}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{subfig}
\usepackage{graphicx, amsmath, amssymb, caption, multirow, overpic, textpos}
\usepackage{tabularx}
\usepackage{nicematrix}  %
\usepackage{makecell}
\usepackage{chngpage}
\usepackage{enumitem}
\usepackage{placeins}

\usepackage{footnote} %
\makesavenoteenv{tabular} %


\def\onedot{.}
\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}
\def\aka{\emph{a.k.a}\onedot}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}



\usepackage[utf8]{inputenc} %
\usepackage[T1]{fontenc}    %
\usepackage{hyperref}       %
\usepackage{url}            %
\usepackage{booktabs}       %
\usepackage{amsfonts}       %
\usepackage{nicefrac}       %
\usepackage{microtype}      %
\usepackage{xcolor}         %
\usepackage{adjustbox}
\usepackage{colortbl}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{wrapfig}
\usepackage{algorithm}
\usepackage{listings}

\usepackage{etoolbox}
\makeatletter
\AfterEndEnvironment{algorithm}{\let\@algcomment\relax}
\AtEndEnvironment{algorithm}{\kern2pt\hrule\relax\vskip3pt\@algcomment}
\let\@algcomment\relax
\newcommand\algcomment[1]{\def\@algcomment{\footnotesize#1}}
\renewcommand\fs@ruled{\def\@fs@cfont{\bfseries}\let\@fs@capt\floatc@ruled
  \def\@fs@pre{\hrule height.8pt depth0pt \kern2pt}%
  \def\@fs@post{}%
  \def\@fs@mid{\kern2pt\hrule\kern2pt}%
  \let\@fs@iftopcapt\iftrue}
\makeatother

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


\usepackage{xspace}

\newcommand{\babeldraw}{Parti\xspace}
\newcommand{\bdraw}{\babeldraw} %
\newcommand{\twenty}{\babeldraw20B\xspace}
\newcommand{\webfit}{FIT400M\xspace}

\newcommand{\todo}[1]{\textcolor{blue}{[TODO: {#1}]}}

\definecolor{red2}{RGB}{252, 54, 65}
\definecolor{darkergreen}{RGB}{21, 152, 56}

\newcommand{\mc}[2]{\multicolumn{#1}{c}{#2}}
\definecolor{Gray}{gray}{0.95}
\newcolumntype{a}{>{\columncolor{Gray}}c}
\newcolumntype{b}{>{\columncolor{white}}c}

\newcommand{\pz}{\hphantom{0}}
\newcommand{\pzz}{\hphantom{00}}

\usepackage{longtable}
\usepackage{caption}
\newcommand{\bcp}{PartiPrompts}
\newcommand{\bcpa}{P$2$}  %
\newcommand{\bcpsize}{1600}
\newcommand{\bcpabstractsize}{46}
\newcommand{\bcpcat}{12}
\newcommand{\bcptrick}{11}
\newcommand{\bcpstyle}[1]{\textsc{#1}}
\newcommand{\thang}[1]{\textcolor{blue}{#1}}
\newcommand{\fid}{7.23}
\newcommand{\fidft}{3.22}
\newcommand{\dalle}{DALL-E}
\newcommand{\cherry}{Growing a Cherry Tree}

\newcommand{\jykoh}[1]{\textcolor{red}{#1}}
\newcommand{\thirdcolwidth}{0.4}
\newcommand{\twobytwocolwidth}{0.2}
\newcommand{\threebythreecolwidth}{0.1333}

\title{Scaling Autoregressive Models for Content-Rich Text-to-Image Generation}
\setcounter{footnote}{3}

\author{
\parbox{\linewidth}{\centering

Jiahui Yu\footnotemark[1]\hspace{.4cm}
Yuanzhong Xu\footnotemark[2]\hspace{.4cm}
Jing Yu Koh\footnotemark[2]\hspace{.4cm}
Thang Luong\footnotemark[2]\hspace{.4cm}
Gunjan Baid\footnotemark[2]\\
Zirui Wang\footnotemark[2]\hspace{.7cm}
Vijay Vasudevan\footnotemark[2]\hspace{.7cm}
Alexander Ku\footnotemark[2]\\

Yinfei Yang\hspace{.2cm}
Burcu Karagol Ayan\hspace{.2cm}
Ben Hutchinson
\\
Wei Han\hspace{.2cm}
Zarana Parekh\hspace{.2cm}
Xin Li\hspace{.2cm}
Han Zhang\hspace{.2cm}\\

Jason Baldridge\footnotemark[2]\hspace{.8cm}
Yonghui Wu\footnotemark[1]
\\
\texttt{\small{\{jiahuiyu, yuanzx, jykoh, thangluong, gunjanbaid, ziruiw, vrv, alexku,\\ jasonbaldridge, yonghui\}@google.com}}\thanks{Correspondence to \texttt{\small{\{jiahuiyu, jasonbaldridge, yonghui\}}@google.com.}}
\\
}\\

\parbox{\linewidth}{\centering \vspace{0.2cm}
\footnotemark[1] \ \ Equal contribution.\hspace{1cm}
\footnotemark[2] \ \ Core contribution.\\
}\\

\parbox{\linewidth}{\centering \vspace{0.2cm}
   Google Research \\
}\\
}

\begin{document}

\maketitle

\begin{figure}[tbh!]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/teaser.jpg}
    \caption{Example images generated by \bdraw. \textbf{Top row}: ``{\it Oil-on-canvas painting of a blue night sky with roiling energy. A fuzzy and bright yellow crescent moon shining at the top. Below the exploding yellow stars and radiating swirls of blue, a distant village sits quietly on the right. Connecting earth and sky is a flame-like cypress tree with curling and swaying branches on the left. A church spire rises as a beacon over rolling blue hills}.'' (a 67-word description of the Starry Night by Vincent van Gogh). \textbf{Middle row}: ``{\it A close-up high-contrast photo of Sydney Opera House sitting next to Eiffel tower, under a blue night sky of roiling energy, exploding yellow stars, and radiating swirls of blue}''. \textbf{Last row}: Similar to the middle row, but with ``{\it anime illustration}'' and different landmarks ({\it the Great Pyramid and the Parthenon}).}
    \label{figs:teaser}
\end{figure}

\begin{abstract}
We present the Pathways~\cite{PathwaysProgram} Autoregressive Text-to-Image (\bdraw) model, which generates high-fidelity photorealistic images and supports content-rich synthesis involving complex compositions and world knowledge. \bdraw treats text-to-image generation as a sequence-to-sequence modeling problem, akin to machine translation, with sequences of image tokens as the target outputs rather than text tokens in another language. This strategy can naturally tap into the rich body of prior work on large language models, which have seen continued advances in capabilities and performance through scaling data and model sizes. Our approach is simple: First, \bdraw uses a Transformer-based image tokenizer, ViT-VQGAN, to encode images as sequences of discrete tokens. Second, we achieve consistent quality improvements by scaling the encoder-decoder Transformer model up to 20B parameters, with a new state-of-the-art zero-shot FID score of \fid{} and finetuned FID score of \fidft{} on MS-COCO. Our detailed analysis on Localized Narratives as well as \bcp{} (\bcpa{}), a new holistic benchmark of over \bcpsize{} English prompts, demonstrate the effectiveness of \bdraw across a wide variety of categories and difficulty aspects. We also explore and highlight limitations of our models in order to define and exemplify key areas of focus for further improvements.
See \href{https://parti.research.google/}{\texttt{parti.research.google}} for high-resolution images.
\end{abstract}

\input{sec1_intro}
\input{sec3_model}
\input{sec4_scaling}
\input{sec4o5__data}
\input{sec5_evaluations}
\input{sec5o5_limitations}
\input{sec2_related_work}
\input{sec6_broader_impacts}
\input{sec8_conclusion}
\input{sec9_ack}

\bibliographystyle{unsrt}
\bibliography{main}


\appendix

\input{appendix_cherry}

\input{appendix_cross}

\input{appendix_qualitative_comparison}

\pagebreak
\input{appendix_bcp}

\input{appendix_human_evals}

\input{appendix_bcp_evals}

\input{appendix_text_pretrain}

\input{appendix_pixelation}

\end{document}
