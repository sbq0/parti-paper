\expandafter\ifx\csname doTocEntry\endcsname\relax \expandafter\endinput\fi
\doTocEntry\toclof{}{\csname a:TocLink\endcsname{1}{x1-3}{}{\numberline {1}{\ignorespaces Example images generated by Parti\xspace  . \textbf  {Top row}: ``{\it  Oil-on-canvas painting of a blue night sky with roiling energy. A fuzzy and bright yellow crescent moon shining at the top. Below the exploding yellow stars and radiating swirls of blue, a distant village sits quietly on the right. Connecting earth and sky is a flame-like cypress tree with curling and swaying branches on the left. A church spire rises as a beacon over rolling blue hills}.'' (a 67-word description of the Starry Night by Vincent van Gogh). \textbf  {Middle row}: ``{\it  A close-up high-contrast photo of Sydney Opera House sitting next to Eiffel tower, under a blue night sky of roiling energy, exploding yellow stars, and radiating swirls of blue}''. \textbf  {Last row}: Similar to the middle row, but with ``{\it  anime illustration}'' and different landmarks ({\it  the Great Pyramid and the Parthenon}).\relax }}}{3}\relax 
\doTocEntry\toclof{}{\csname a:TocLink\endcsname{1}{x1-5}{}{\numberline {2}{\ignorespaces Selected Parti\xspace  images. See Section \ref  {sec:selected_discussion} for discussion.\relax }}}{6}\relax 
\doTocEntry\tocsection{1}{\csname a:TocLink\endcsname{1}{x1-10001}{QQ2-1-1}{Introduction}}{7}\relax 
\doTocEntry\toclof{}{\csname a:TocLink\endcsname{1}{x1-1003}{}{\numberline {3}{\ignorespaces Overview of Parti\xspace  sequence-to-sequence autoregressive model (left) for text-to-image generation with ViT-VQGAN as the image tokenizer\nobreakspace  {}\cite  {yu2021vector} (right).\relax }}}{10}\relax 
\doTocEntry\tocsection{2}{\csname a:TocLink\endcsname{1}{x1-20002}{QQ2-1-2}{Parti\xspace  Model}}{11}\relax 
\doTocEntry\tocsubsection{2.1}{\csname a:TocLink\endcsname{1}{x1-30002.1}{QQ2-1-3}{Image Tokenizer}}{11}\relax 
\doTocEntry\toclof{}{\csname a:TocLink\endcsname{1}{x1-3002}{}{\numberline {4}{\ignorespaces A learned super-resolution module to upsample \unhbox \voidb@x \bgroup \nested:math \PicMath $256\times 256$ \EndPicMath \egroup  images to higher-resolution \unhbox \voidb@x \bgroup \nested:math \PicMath $1024\times 1024$ \EndPicMath \egroup  ones based on a frozen ViT-VQGAN image tokenizer. The super-resolution module takes \unhbox \voidb@x \bgroup \nested:math \PicMath $256\times 256$ \EndPicMath \egroup  images as inputs without conditioning on text inputs.\relax }}}{14}\relax 
\doTocEntry\tocsubsection{2.2}{\csname a:TocLink\endcsname{1}{x1-40002.2}{QQ2-1-4}{Encoder-Decoder for Text-to-Image Generation}}{15}\relax 
\doTocEntry\toclot{}{\csname a:TocLink\endcsname{1}{x1-4002}{}{\numberline {1}{\ignorespaces  Size variants of Parti\xspace  . Both encoder and decoder are based on Transformers\nobreakspace  {}\cite  {vaswani2017attention}. The self-attention layer in decoder transformer is causally masked. Parameters of ViT-VQGAN image tokenization are not included in the total parameter count and can be found in Section\nobreakspace  {}\let \prOteCt \relax \let \prOteCt \relax \Protect \::ref {secs:tokenizer}.\relax }}}{17}\relax 
\doTocEntry\tocsubsection{2.3}{\csname a:TocLink\endcsname{1}{x1-50002.3}{QQ2-1-5}{Text Encoder Pretraining}}{18}\relax 
\doTocEntry\tocsubsection{2.4}{\csname a:TocLink\endcsname{1}{x1-60002.4}{QQ2-1-6}{Classifier-Free Guidance and Reranking}}{18}\relax 
\doTocEntry\toclof{}{\csname a:TocLink\endcsname{1}{x1-6003}{}{\numberline {5}{\ignorespaces 4-way in-layer model parallelism with fully partitioned activations used to scale the 3B model training. The figure shows a simplified Transformer feed-forward layer (with the sequence dimension omitted); each color represents data on one device. We also use 128-way data parallelism.\relax }}}{21}\relax 
\doTocEntry\tocsection{3}{\csname a:TocLink\endcsname{1}{x1-70003}{QQ2-1-7}{Scaling}}{22}\relax 
\doTocEntry\toclof{}{\csname a:TocLink\endcsname{1}{x1-7002}{}{\numberline {6}{\ignorespaces An illustration of 16-stage GSPMD pipelines used to scale the 20B model training. The figure shows how the 16 devices are used for data parallelism in the quantizer, embedding and softmax layers, but repurposed for pipelining in the encoder and decoder layers. Each color represents data or layer assigned to one device. The decoder uses 4-round circular schedule to further reduce the pipeline bubble ratio. On top of this, we use additional 64-way data parallelism for all layers.\relax }}}{24}\relax 
\doTocEntry\tocsection{4}{\csname a:TocLink\endcsname{1}{x1-80004}{QQ2-1-8}{Training and Evaluation Datasets}}{25}\relax 
\doTocEntry\tocsubsection{4.1}{\csname a:TocLink\endcsname{1}{x1-90004.1}{QQ2-1-9}{Training Datasets}}{25}\relax 
\doTocEntry\tocsubsection{4.2}{\csname a:TocLink\endcsname{1}{x1-100004.2}{QQ2-1-10}{Evaluation Datasets}}{26}\relax 
\doTocEntry\tocsubsection{4.3}{\csname a:TocLink\endcsname{1}{x1-110004.3}{QQ2-1-11}{PartiPrompts{}}}{29}\relax 
